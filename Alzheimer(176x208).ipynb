{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f3ec65",
   "metadata": {},
   "source": [
    "# DATA:https://www.kaggle.com/mdsafayet/multiclass-disease-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e925411",
   "metadata": {},
   "source": [
    "## Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf86be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, metrics\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8796c47",
   "metadata": {},
   "source": [
    "## Display a sample image in 42x42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c5d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e9daedaf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageOne = cv2.imread(\"C:/Users/Fatih/Downloads/alzheimer data/Alzheimer MildDemented/mildDem48.jpg\")\n",
    "imageOne = cv2.resize(imageOne, (42, 42), interpolation = cv2.INTER_AREA)\n",
    "imageOne = np.array(imageOne)\n",
    "imageOne = imageOne.astype(\"float32\")\n",
    "imageOne /= 255\n",
    "plt.imshow(imageOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847be10",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d89306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparingImages(dataPath, labels, newTrainPath, newTestPath, newValidationPath, validationSplit, testSplit): \n",
    "    # this function for creating validation Image set and also creating new test Image set\n",
    "    trainingFrequencies = []\n",
    "    for label in labels:\n",
    "        trainingFileNames = os.listdir(dataPath+\"Alzheimer \"+label +\"/\")\n",
    "        validationFileNames = random.sample(trainingFileNames,int(len(trainingFileNames)*validationSplit))\n",
    "        trainingFileNamesBeforeTestSplit = [file for file in trainingFileNames if file not in validationFileNames]\n",
    "        testFileNames = random.sample(trainingFileNamesBeforeTestSplit,int(len(trainingFileNamesBeforeTestSplit)*((1+validationSplit) * testSplit)))\n",
    "        newTrainingFileNames = [file for file in trainingFileNamesBeforeTestSplit if file not in testFileNames]\n",
    "        for file in newTrainingFileNames:\n",
    "            shutil.copy(dataPath + \"Alzheimer \" + label + \"/\" + file, newTrainPath + label + \"/\" + file)\n",
    "        print(\"Train images transfer complate for label: \" + label + \"number of transferred images = \" + str(len(newTrainingFileNames)))\n",
    "        for file in validationFileNames:\n",
    "            shutil.copy(dataPath + \"Alzheimer \" + label + \"/\" + file, newValidationPath + label + \"/\" + file)\n",
    "        print(\"Train images transfer complate for label: \" + label + \"number of transferred images = \" + str(len(validationFileNames)))\n",
    "        for file in testFileNames:\n",
    "            shutil.copy(dataPath + \"Alzheimer \" + label + \"/\" + file, newTestPath + label + \"/\" + file)\n",
    "        print(\"Train images transfer complate for label: \" + label + \"number of transferred images = \" + str(len(testFileNames)))\n",
    "        print(\"Frequency of \" + label + \": \" + str(len(newTrainingFileNames)))\n",
    "        trainingFrequencies.append(len(newTrainingFileNames))\n",
    "    return trainingFrequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e382ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDictionaries(path, labels, datasetTypes = [\"train\",\"test\",\"validation\"]):\n",
    "    if path[-1] != \"/\":\n",
    "        path = path + \"/\"\n",
    "    for dataset in datasetTypes:\n",
    "        datasetPath = os.path.join(path,dataset)\n",
    "        os.mkdir(datasetPath)\n",
    "        for label in labels:\n",
    "            labelPath = os.path.join(datasetPath,label)\n",
    "            os.mkdir(labelPath)\n",
    "            print(f\"Dictionary {labelPath} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8594aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyImagesUntillSameNumberOfImage(trainingFrequencies, labels, TrainPath):\n",
    "    #this function provides increasae number of samples at each labels to maximum number of trainingFrequencies\n",
    "    trainLabelFrequenciesArr = np.array(trainingFrequencies)\n",
    "    targetSample = np.max(trainLabelFrequenciesArr)\n",
    "    for i in range(4):\n",
    "        imageCounter = 0\n",
    "        currentLabel = labels[i]\n",
    "        missingSamples = targetSample - trainLabelFrequenciesArr[i]\n",
    "        filenames = os.listdir(TrainPath+currentLabel+\"/\")\n",
    "        numberOfFilled = np.zeros(len(filenames))\n",
    "        while np.sum(numberOfFilled) < missingSamples:\n",
    "            index = np.random.randint(0,len(filenames))\n",
    "            shutil.copy(TrainPath+currentLabel+\"/\"+filenames[index],\n",
    "                        TrainPath+currentLabel+\"/\"+filenames[index].replace(\".jpg\",\"_copy_\"+str(int(numberOfFilled[index]+1))+\".jpg\"))\n",
    "            numberOfFilled[index] += 1\n",
    "            imageCounter += 1\n",
    "        print(f\"{imageCounter} Images copied to: {TrainPath+currentLabel+'/'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31fa868a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (Temp/ipykernel_5656/12159153.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Fatih\\AppData\\Local\\Temp/ipykernel_5656/12159153.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def testModel(model, testData, saveGraph = False, matrixRoundSize = 3, timeRoundSize = 3, labels):\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def testModel(model, testData, saveGraph = False, matrixRoundSize = 3, timeRoundSize = 3, labels):\n",
    "    predictions= []\n",
    "    realValues= []\n",
    "    i = 0\n",
    "    timeBeforePrediction = time.time()\n",
    "    for batch, label in testData:\n",
    "        prediction = model.predict(batch).argmax(axis = -1)\n",
    "        predictions.extend(prediction)\n",
    "        realValues.extend(label.argmax(axis = -1))\n",
    "        i += 1\n",
    "        if i > len(testData.labels):\n",
    "            break\n",
    "    timeAfterPrediction = time.time()\n",
    "    totalTime = round((timeAfterPrediction - timeBeforePrediction), timeRoundSize)\n",
    "    averageTime = round((timeAfterPrediction - timeBeforePrediction) / len(testData.labels), timeRoundSize)\n",
    "    print(f\"{len(testData.labels)} image(s) predicted at {totalTime} sec\")\n",
    "    print(f\"Average predict time equals to =  {averageTime} sec\")\n",
    "    confusionMatrix = confusion_matrix(realValues, predictions)\n",
    "    relativeConfusionMatrix = confusionMatrix / np.sum(confusionMatrix, axis = 0)\n",
    "    figure, axis = plt.subplots(1,2,figsize=(20,20))\n",
    "    image1 = axis[0].imshow(confusionMatrix, cmap = plt.get_cmap(\"GnBu\"))\n",
    "    image2 = axis[1].imshow(confusionMatrix, cmap = plt.get_cmap(\"GnBu\"))\n",
    "    for (i, j), k in np.ndenumerate(confusionMatrix):\n",
    "        axis[0].text(j, i, s = str(k), ha = \"center\", va = \"center\")\n",
    "        axis[0].set_xticks(np.arange(0,len(labels), 1))\n",
    "        axis[0].set_xticklabels(labels)\n",
    "        axis[0].set_yticks(np.arange(0,len(labels), 1))\n",
    "        axis[0].set_yticklabels(labels)\n",
    "        axis[0].set_title(\"Confusion Matrix\")\n",
    "    for (i, j), k in np.ndenumerate(relativeConfusionMatrix):\n",
    "        axis[1].text(j, i, s = str(np.round(k, matrixRoundSize)), ha = \"center\", va = \"center\")\n",
    "        axis[1].set_xticks(np.arange(0,len(labels), 1))\n",
    "        axis[1].set_xticklabels(labels)\n",
    "        axis[1].set_yticks(np.arange(0,len(labels), 1))\n",
    "        axis[1].set_yticklabels(labels)\n",
    "        plt.subplots_adjust(wspace = 0.5)\n",
    "        axis[1].set_title(\"Confusion Matrix\")\n",
    "    while saveGraph:\n",
    "        path = input(r\"Enter path where you want to save the figure:\")\n",
    "        try:\n",
    "            if path[-1] != \"/\":\n",
    "                path = path + \"/\"\n",
    "            print(path)\n",
    "            figure.savefig(path + \"ConfusionMatrix and relativeConfusionMatrix of model.png\")\n",
    "            saveGraph = False\n",
    "        except:\n",
    "            print(\"Saving figure could not complete do you want to try again ?\")\n",
    "            isContinue = input(\"1 : Yes | any text except '1' : No\")\n",
    "            if isContinue != \"1\":\n",
    "                saveGraph = False\n",
    "    return confusion_matrix(realValues, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c78ff",
   "metadata": {},
   "source": [
    "## Creating Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58dbc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"C:/Users/Fatih/Downloads/alzheimer data/\"\n",
    "newDataPath = \"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/\"\n",
    "validationSplit = 1/6\n",
    "testSplit = 1/6\n",
    "newTrainPath = newDataPath + \"train/\"\n",
    "newTestPath = newDataPath + \"test/\"\n",
    "newValidationPath = newDataPath + \"validation/\"\n",
    "labels = [\"NonDemented\", \"VeryMildDemented\", \"MildDemented\", \"ModerateDemented\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e211d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train\\NonDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train\\VeryMildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train\\MildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train\\ModerateDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/test\\NonDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/test\\VeryMildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/test\\MildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/test\\ModerateDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/validation\\NonDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/validation\\VeryMildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/validation\\MildDemented created\n",
      "Dictionary C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/validation\\ModerateDemented created\n"
     ]
    }
   ],
   "source": [
    "createDictionaries(newDataPath, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9abe53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images transfer complate for label: NonDementednumber of transferred images = 2149\n",
      "Train images transfer complate for label: NonDementednumber of transferred images = 533\n",
      "Train images transfer complate for label: NonDementednumber of transferred images = 518\n",
      "Frequency of NonDemented: 2149\n",
      "Train images transfer complate for label: VeryMildDementednumber of transferred images = 1504\n",
      "Train images transfer complate for label: VeryMildDementednumber of transferred images = 373\n",
      "Train images transfer complate for label: VeryMildDementednumber of transferred images = 363\n",
      "Frequency of VeryMildDemented: 1504\n",
      "Train images transfer complate for label: MildDementednumber of transferred images = 602\n",
      "Train images transfer complate for label: MildDementednumber of transferred images = 149\n",
      "Train images transfer complate for label: MildDementednumber of transferred images = 145\n",
      "Frequency of MildDemented: 602\n",
      "Train images transfer complate for label: ModerateDementednumber of transferred images = 44\n",
      "Train images transfer complate for label: ModerateDementednumber of transferred images = 10\n",
      "Train images transfer complate for label: ModerateDementednumber of transferred images = 10\n",
      "Frequency of ModerateDemented: 44\n"
     ]
    }
   ],
   "source": [
    "trainingFrequencies = preparingImages(dataPath, labels, newTrainPath, newTestPath, newValidationPath, validationSplit, testSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621378ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Images copied to: C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train/NonDemented/\n",
      "645 Images copied to: C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train/VeryMildDemented/\n",
      "1547 Images copied to: C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train/MildDemented/\n",
      "2105 Images copied to: C:/Users/Fatih/Desktop/python/machine learning/alzheimer/alzheimer data/new/train/ModerateDemented/\n"
     ]
    }
   ],
   "source": [
    "copyImagesUntillSameNumberOfImage(trainingFrequencies, labels, newTrainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c8f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataGenerator = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range=0.1,\n",
    "                                       width_shift_range=0.1,\n",
    "                                       height_shift_range=0.1,\n",
    "                                       shear_range=0.1,\n",
    "                                       brightness_range=[0.8,1.2],\n",
    "                                       zoom_range=0.1,\n",
    "                                       horizontal_flip=False,\n",
    "                                       fill_mode=\"nearest\")\n",
    "testDataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "validationDataGenerator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d10ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8596 images belonging to 4 classes.\n",
      "Found 1036 images belonging to 4 classes.\n",
      "Found 1065 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "trainData = trainDataGenerator.flow_from_directory(newTrainPath, (176,208), batch_size=100, class_mode=\"categorical\")\n",
    "testData = testDataGenerator.flow_from_directory(newTestPath, (176,208), batch_size=1, class_mode=\"categorical\")\n",
    "validationData = validationDataGenerator.flow_from_directory(newValidationPath, (176,208), batch_size=100, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4d62d",
   "metadata": {},
   "source": [
    "## Creating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c043f4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 174, 206, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 87, 103, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 85, 101, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 42, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 11, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12672)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1622144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,863,492\n",
      "Trainable params: 1,863,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(176,208,3)))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "BatchNormalization()\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "             optimizer = optimizers.Adam(lr=0.001, beta_1= 0.9, beta_2=0.999, epsilon=1e-8, decay=0.0),\n",
    "             metrics = metrics.CategoricalAccuracy(name=\"categorical_accuracy\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec2284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24973, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 195s - loss: 1.3848 - categorical_accuracy: 0.2691 - val_loss: 1.2497 - val_categorical_accuracy: 0.3493\n",
      "Epoch 2/250\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.24973 to 0.95016, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 1.1120 - categorical_accuracy: 0.4994 - val_loss: 0.9502 - val_categorical_accuracy: 0.5324\n",
      "Epoch 3/250\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95016 to 0.92864, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.8104 - categorical_accuracy: 0.6297 - val_loss: 0.9286 - val_categorical_accuracy: 0.5587\n",
      "Epoch 4/250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.92864\n",
      "86/86 - 188s - loss: 0.7101 - categorical_accuracy: 0.6704 - val_loss: 1.1124 - val_categorical_accuracy: 0.4845\n",
      "Epoch 5/250\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.92864 to 0.88263, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 187s - loss: 0.6526 - categorical_accuracy: 0.7017 - val_loss: 0.8826 - val_categorical_accuracy: 0.6150\n",
      "Epoch 6/250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.88263\n",
      "86/86 - 188s - loss: 0.6126 - categorical_accuracy: 0.7177 - val_loss: 0.9860 - val_categorical_accuracy: 0.5531\n",
      "Epoch 7/250\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.88263 to 0.81422, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.5890 - categorical_accuracy: 0.7317 - val_loss: 0.8142 - val_categorical_accuracy: 0.6169\n",
      "Epoch 8/250\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.81422\n",
      "86/86 - 187s - loss: 0.5647 - categorical_accuracy: 0.7445 - val_loss: 0.8163 - val_categorical_accuracy: 0.6451\n",
      "Epoch 9/250\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.81422 to 0.72961, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 187s - loss: 0.5387 - categorical_accuracy: 0.7584 - val_loss: 0.7296 - val_categorical_accuracy: 0.6742\n",
      "Epoch 10/250\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72961\n",
      "86/86 - 187s - loss: 0.5129 - categorical_accuracy: 0.7722 - val_loss: 0.9424 - val_categorical_accuracy: 0.6009\n",
      "Epoch 11/250\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72961\n",
      "86/86 - 186s - loss: 0.4779 - categorical_accuracy: 0.7911 - val_loss: 0.8409 - val_categorical_accuracy: 0.6460\n",
      "Epoch 12/250\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.72961 to 0.60429, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 186s - loss: 0.4619 - categorical_accuracy: 0.8028 - val_loss: 0.6043 - val_categorical_accuracy: 0.7239\n",
      "Epoch 13/250\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.60429 to 0.56147, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.4530 - categorical_accuracy: 0.8034 - val_loss: 0.5615 - val_categorical_accuracy: 0.7493\n",
      "Epoch 14/250\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.56147\n",
      "86/86 - 187s - loss: 0.4270 - categorical_accuracy: 0.8120 - val_loss: 0.7215 - val_categorical_accuracy: 0.6854\n",
      "Epoch 15/250\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.56147\n",
      "86/86 - 188s - loss: 0.3932 - categorical_accuracy: 0.8335 - val_loss: 0.8484 - val_categorical_accuracy: 0.6563\n",
      "Epoch 16/250\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.56147\n",
      "86/86 - 187s - loss: 0.3797 - categorical_accuracy: 0.8391 - val_loss: 0.6693 - val_categorical_accuracy: 0.7202\n",
      "Epoch 17/250\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.56147 to 0.52198, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.3562 - categorical_accuracy: 0.8473 - val_loss: 0.5220 - val_categorical_accuracy: 0.7803\n",
      "Epoch 18/250\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52198 to 0.50258, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.3603 - categorical_accuracy: 0.8441 - val_loss: 0.5026 - val_categorical_accuracy: 0.7690\n",
      "Epoch 19/250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50258\n",
      "86/86 - 187s - loss: 0.3305 - categorical_accuracy: 0.8605 - val_loss: 0.8069 - val_categorical_accuracy: 0.6901\n",
      "Epoch 20/250\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.50258 to 0.43596, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.3060 - categorical_accuracy: 0.8690 - val_loss: 0.4360 - val_categorical_accuracy: 0.8150\n",
      "Epoch 21/250\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.43596\n",
      "86/86 - 187s - loss: 0.2791 - categorical_accuracy: 0.8844 - val_loss: 0.5475 - val_categorical_accuracy: 0.7746\n",
      "Epoch 22/250\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.43596 to 0.41984, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.2829 - categorical_accuracy: 0.8830 - val_loss: 0.4198 - val_categorical_accuracy: 0.8113\n",
      "Epoch 23/250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.41984\n",
      "86/86 - 187s - loss: 0.2619 - categorical_accuracy: 0.8926 - val_loss: 0.4735 - val_categorical_accuracy: 0.7944\n",
      "Epoch 24/250\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.41984 to 0.40847, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.2664 - categorical_accuracy: 0.8920 - val_loss: 0.4085 - val_categorical_accuracy: 0.8347\n",
      "Epoch 25/250\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.40847 to 0.40207, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.2359 - categorical_accuracy: 0.9033 - val_loss: 0.4021 - val_categorical_accuracy: 0.8216\n",
      "Epoch 26/250\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.40207 to 0.36274, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.2282 - categorical_accuracy: 0.9041 - val_loss: 0.3627 - val_categorical_accuracy: 0.8366\n",
      "Epoch 27/250\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.36274\n",
      "86/86 - 188s - loss: 0.2096 - categorical_accuracy: 0.9144 - val_loss: 0.3711 - val_categorical_accuracy: 0.8460\n",
      "Epoch 28/250\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.36274\n",
      "86/86 - 188s - loss: 0.2019 - categorical_accuracy: 0.9188 - val_loss: 0.3923 - val_categorical_accuracy: 0.8545\n",
      "Epoch 29/250\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.36274\n",
      "86/86 - 188s - loss: 0.1977 - categorical_accuracy: 0.9193 - val_loss: 0.4701 - val_categorical_accuracy: 0.8075\n",
      "Epoch 30/250\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.36274 to 0.23186, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.1916 - categorical_accuracy: 0.9221 - val_loss: 0.2319 - val_categorical_accuracy: 0.9023\n",
      "Epoch 31/250\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23186 to 0.22648, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.1828 - categorical_accuracy: 0.9280 - val_loss: 0.2265 - val_categorical_accuracy: 0.9061\n",
      "Epoch 32/250\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.22648\n",
      "86/86 - 188s - loss: 0.1798 - categorical_accuracy: 0.9297 - val_loss: 0.3500 - val_categorical_accuracy: 0.8667\n",
      "Epoch 33/250\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.22648 to 0.21889, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.1673 - categorical_accuracy: 0.9340 - val_loss: 0.2189 - val_categorical_accuracy: 0.9080\n",
      "Epoch 34/250\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21889\n",
      "86/86 - 189s - loss: 0.1579 - categorical_accuracy: 0.9390 - val_loss: 0.3420 - val_categorical_accuracy: 0.8685\n",
      "Epoch 35/250\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.21889\n",
      "86/86 - 188s - loss: 0.1433 - categorical_accuracy: 0.9444 - val_loss: 0.2743 - val_categorical_accuracy: 0.8892\n",
      "Epoch 36/250\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.21889 to 0.16896, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.1524 - categorical_accuracy: 0.9404 - val_loss: 0.1690 - val_categorical_accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16896\n",
      "86/86 - 187s - loss: 0.1338 - categorical_accuracy: 0.9482 - val_loss: 0.2247 - val_categorical_accuracy: 0.9164\n",
      "Epoch 38/250\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16896\n",
      "86/86 - 187s - loss: 0.1378 - categorical_accuracy: 0.9477 - val_loss: 0.2674 - val_categorical_accuracy: 0.8930\n",
      "Epoch 39/250\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16896\n",
      "86/86 - 187s - loss: 0.1395 - categorical_accuracy: 0.9450 - val_loss: 0.2554 - val_categorical_accuracy: 0.9033\n",
      "Epoch 40/250\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16896\n",
      "86/86 - 188s - loss: 0.1225 - categorical_accuracy: 0.9542 - val_loss: 0.2301 - val_categorical_accuracy: 0.9183\n",
      "Epoch 41/250\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16896\n",
      "86/86 - 188s - loss: 0.1094 - categorical_accuracy: 0.9589 - val_loss: 0.3011 - val_categorical_accuracy: 0.8854\n",
      "Epoch 42/250\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16896\n",
      "86/86 - 188s - loss: 0.1180 - categorical_accuracy: 0.9558 - val_loss: 0.3330 - val_categorical_accuracy: 0.8892\n",
      "Epoch 43/250\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16896\n",
      "86/86 - 188s - loss: 0.1169 - categorical_accuracy: 0.9543 - val_loss: 0.1761 - val_categorical_accuracy: 0.9305\n",
      "Epoch 44/250\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16896\n",
      "86/86 - 188s - loss: 0.1147 - categorical_accuracy: 0.9571 - val_loss: 0.3003 - val_categorical_accuracy: 0.8911\n",
      "Epoch 45/250\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16896\n",
      "86/86 - 187s - loss: 0.1095 - categorical_accuracy: 0.9601 - val_loss: 0.2241 - val_categorical_accuracy: 0.9117\n",
      "Epoch 46/250\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16896\n",
      "86/86 - 187s - loss: 0.1093 - categorical_accuracy: 0.9588 - val_loss: 0.2252 - val_categorical_accuracy: 0.9268\n",
      "Epoch 47/250\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.16896\n",
      "86/86 - 186s - loss: 0.0998 - categorical_accuracy: 0.9641 - val_loss: 0.1864 - val_categorical_accuracy: 0.9305\n",
      "Epoch 48/250\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16896\n",
      "86/86 - 186s - loss: 0.1005 - categorical_accuracy: 0.9622 - val_loss: 0.2233 - val_categorical_accuracy: 0.9174\n",
      "Epoch 49/250\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16896\n",
      "86/86 - 192s - loss: 0.0957 - categorical_accuracy: 0.9653 - val_loss: 0.2108 - val_categorical_accuracy: 0.9211\n",
      "Epoch 50/250\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.16896 to 0.16870, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 187s - loss: 0.0964 - categorical_accuracy: 0.9631 - val_loss: 0.1687 - val_categorical_accuracy: 0.9418\n",
      "Epoch 51/250\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.16870\n",
      "86/86 - 187s - loss: 0.0931 - categorical_accuracy: 0.9651 - val_loss: 0.2679 - val_categorical_accuracy: 0.9127\n",
      "Epoch 52/250\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.16870\n",
      "86/86 - 188s - loss: 0.0800 - categorical_accuracy: 0.9692 - val_loss: 0.1702 - val_categorical_accuracy: 0.9521\n",
      "Epoch 53/250\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.16870 to 0.13740, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 188s - loss: 0.0833 - categorical_accuracy: 0.9710 - val_loss: 0.1374 - val_categorical_accuracy: 0.9549\n",
      "Epoch 54/250\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.13740\n",
      "86/86 - 188s - loss: 0.0856 - categorical_accuracy: 0.9687 - val_loss: 0.2838 - val_categorical_accuracy: 0.9014\n",
      "Epoch 55/250\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.13740\n",
      "86/86 - 189s - loss: 0.0853 - categorical_accuracy: 0.9680 - val_loss: 0.2030 - val_categorical_accuracy: 0.9390\n",
      "Epoch 56/250\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.13740\n",
      "86/86 - 188s - loss: 0.0763 - categorical_accuracy: 0.9728 - val_loss: 0.1484 - val_categorical_accuracy: 0.9474\n",
      "Epoch 57/250\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.13740\n",
      "86/86 - 187s - loss: 0.0760 - categorical_accuracy: 0.9713 - val_loss: 0.1399 - val_categorical_accuracy: 0.9484\n",
      "Epoch 58/250\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.13740\n",
      "86/86 - 188s - loss: 0.0816 - categorical_accuracy: 0.9706 - val_loss: 0.1763 - val_categorical_accuracy: 0.9296\n",
      "Epoch 59/250\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.13740\n",
      "86/86 - 187s - loss: 0.0798 - categorical_accuracy: 0.9714 - val_loss: 0.1509 - val_categorical_accuracy: 0.9427\n",
      "Epoch 60/250\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.13740\n",
      "86/86 - 187s - loss: 0.0773 - categorical_accuracy: 0.9724 - val_loss: 0.3084 - val_categorical_accuracy: 0.9033\n",
      "Epoch 61/250\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.13740\n",
      "86/86 - 187s - loss: 0.0766 - categorical_accuracy: 0.9727 - val_loss: 0.1739 - val_categorical_accuracy: 0.9315\n",
      "Epoch 62/250\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.13740 to 0.13570, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 187s - loss: 0.0767 - categorical_accuracy: 0.9703 - val_loss: 0.1357 - val_categorical_accuracy: 0.9596\n",
      "Epoch 63/250\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.13570\n",
      "86/86 - 188s - loss: 0.0648 - categorical_accuracy: 0.9775 - val_loss: 0.1423 - val_categorical_accuracy: 0.9606\n",
      "Epoch 64/250\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.13570\n",
      "86/86 - 188s - loss: 0.0674 - categorical_accuracy: 0.9752 - val_loss: 0.1863 - val_categorical_accuracy: 0.9418\n",
      "Epoch 65/250\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.13570\n",
      "86/86 - 188s - loss: 0.0678 - categorical_accuracy: 0.9751 - val_loss: 0.1767 - val_categorical_accuracy: 0.9427\n",
      "Epoch 66/250\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.13570\n",
      "86/86 - 188s - loss: 0.0689 - categorical_accuracy: 0.9729 - val_loss: 0.1792 - val_categorical_accuracy: 0.9352\n",
      "Epoch 67/250\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.13570 to 0.13262, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 189s - loss: 0.0622 - categorical_accuracy: 0.9787 - val_loss: 0.1326 - val_categorical_accuracy: 0.9643\n",
      "Epoch 68/250\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.13262\n",
      "86/86 - 206s - loss: 0.0625 - categorical_accuracy: 0.9779 - val_loss: 0.1563 - val_categorical_accuracy: 0.9531\n",
      "Epoch 69/250\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.13262\n",
      "86/86 - 204s - loss: 0.0692 - categorical_accuracy: 0.9768 - val_loss: 0.2108 - val_categorical_accuracy: 0.9437\n",
      "Epoch 70/250\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.13262\n",
      "86/86 - 200s - loss: 0.0629 - categorical_accuracy: 0.9796 - val_loss: 0.1675 - val_categorical_accuracy: 0.9493\n",
      "Epoch 71/250\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.13262\n",
      "86/86 - 192s - loss: 0.0663 - categorical_accuracy: 0.9766 - val_loss: 0.1587 - val_categorical_accuracy: 0.9606\n",
      "Epoch 72/250\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.13262\n",
      "86/86 - 188s - loss: 0.0673 - categorical_accuracy: 0.9746 - val_loss: 0.1681 - val_categorical_accuracy: 0.9502\n",
      "Epoch 73/250\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.13262\n",
      "86/86 - 187s - loss: 0.0555 - categorical_accuracy: 0.9812 - val_loss: 0.1491 - val_categorical_accuracy: 0.9521\n",
      "Epoch 74/250\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.13262\n",
      "86/86 - 187s - loss: 0.0595 - categorical_accuracy: 0.9774 - val_loss: 0.1365 - val_categorical_accuracy: 0.9577\n",
      "Epoch 75/250\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.13262\n",
      "86/86 - 187s - loss: 0.0508 - categorical_accuracy: 0.9808 - val_loss: 0.1581 - val_categorical_accuracy: 0.9427\n",
      "Epoch 76/250\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.13262\n",
      "86/86 - 186s - loss: 0.0605 - categorical_accuracy: 0.9773 - val_loss: 0.2549 - val_categorical_accuracy: 0.9258\n",
      "Epoch 77/250\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.13262\n",
      "86/86 - 194s - loss: 0.0586 - categorical_accuracy: 0.9785 - val_loss: 0.2236 - val_categorical_accuracy: 0.9305\n",
      "Epoch 78/250\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.13262\n",
      "86/86 - 191s - loss: 0.0664 - categorical_accuracy: 0.9765 - val_loss: 0.1831 - val_categorical_accuracy: 0.9315\n",
      "Epoch 79/250\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.13262\n",
      "86/86 - 189s - loss: 0.0483 - categorical_accuracy: 0.9816 - val_loss: 0.2255 - val_categorical_accuracy: 0.9258\n",
      "Epoch 80/250\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.13262\n",
      "86/86 - 191s - loss: 0.0491 - categorical_accuracy: 0.9836 - val_loss: 0.1440 - val_categorical_accuracy: 0.9559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/250\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.13262 to 0.11557, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 187s - loss: 0.0447 - categorical_accuracy: 0.9819 - val_loss: 0.1156 - val_categorical_accuracy: 0.9681\n",
      "Epoch 82/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4524/2381268709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m hist = model.fit(trainData,\n\u001b[0m\u001b[0;32m      8\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(mode=\"min\",verbose=1,patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath=\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\" + 'alzheimerModel176x208.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 250\n",
    "batchSize = 100\n",
    "\n",
    "hist = model.fit(trainData,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batchSize,\n",
    "                 validation_data = validationData,\n",
    "                 callbacks=[earlyStopping,checkpointer], verbose=2)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\" + 'alzheimerModel176x208.json', 'w') as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361a95d",
   "metadata": {},
   "source": [
    "I stop train manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "511adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\")\n",
    "lastCheckpoint = tf.keras.models.load_model(\"alzheimerModel176x208.h5\")\n",
    "labels = [\"MildDemented\", \"ModerateDemented\", \"NonDemented\", \"VeryMildDemented\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "183a4c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15746, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 184s - loss: 0.0512 - categorical_accuracy: 0.9826 - val_loss: 0.1575 - val_categorical_accuracy: 0.9559\n",
      "Epoch 2/75\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15746\n",
      "86/86 - 206s - loss: 0.0437 - categorical_accuracy: 0.9846 - val_loss: 0.1761 - val_categorical_accuracy: 0.9418\n",
      "Epoch 3/75\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15746 to 0.12310, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 207s - loss: 0.0416 - categorical_accuracy: 0.9851 - val_loss: 0.1231 - val_categorical_accuracy: 0.9653\n",
      "Epoch 4/75\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12310\n",
      "86/86 - 206s - loss: 0.0504 - categorical_accuracy: 0.9820 - val_loss: 0.2339 - val_categorical_accuracy: 0.9239\n",
      "Epoch 5/75\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12310\n",
      "86/86 - 209s - loss: 0.0469 - categorical_accuracy: 0.9835 - val_loss: 0.1666 - val_categorical_accuracy: 0.9455\n",
      "Epoch 6/75\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12310\n",
      "86/86 - 206s - loss: 0.0425 - categorical_accuracy: 0.9855 - val_loss: 0.2874 - val_categorical_accuracy: 0.9117\n",
      "Epoch 7/75\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12310\n",
      "86/86 - 201s - loss: 0.0468 - categorical_accuracy: 0.9824 - val_loss: 0.1426 - val_categorical_accuracy: 0.9615\n",
      "Epoch 8/75\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12310\n",
      "86/86 - 213s - loss: 0.0574 - categorical_accuracy: 0.9778 - val_loss: 0.1311 - val_categorical_accuracy: 0.9559\n",
      "Epoch 9/75\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12310\n",
      "86/86 - 208s - loss: 0.0453 - categorical_accuracy: 0.9845 - val_loss: 0.1380 - val_categorical_accuracy: 0.9587\n",
      "Epoch 10/75\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12310\n",
      "86/86 - 215s - loss: 0.0407 - categorical_accuracy: 0.9862 - val_loss: 0.1579 - val_categorical_accuracy: 0.9577\n",
      "Epoch 11/75\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12310\n",
      "86/86 - 218s - loss: 0.0504 - categorical_accuracy: 0.9831 - val_loss: 0.1644 - val_categorical_accuracy: 0.9446\n",
      "Epoch 12/75\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12310 to 0.12167, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 202s - loss: 0.0367 - categorical_accuracy: 0.9879 - val_loss: 0.1217 - val_categorical_accuracy: 0.9540\n",
      "Epoch 13/75\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12167 to 0.09011, saving model to C:/Users/Fatih/Desktop/python/machine learning/alzheimer\\alzheimerModel176x208.h5\n",
      "86/86 - 205s - loss: 0.0364 - categorical_accuracy: 0.9858 - val_loss: 0.0901 - val_categorical_accuracy: 0.9728\n",
      "Epoch 14/75\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.09011\n",
      "86/86 - 218s - loss: 0.0423 - categorical_accuracy: 0.9851 - val_loss: 0.1640 - val_categorical_accuracy: 0.9502\n",
      "Epoch 15/75\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.09011\n",
      "86/86 - 203s - loss: 0.0597 - categorical_accuracy: 0.9778 - val_loss: 0.1699 - val_categorical_accuracy: 0.9324\n",
      "Epoch 16/75\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09011\n",
      "86/86 - 194s - loss: 0.0481 - categorical_accuracy: 0.9835 - val_loss: 0.1109 - val_categorical_accuracy: 0.9643\n",
      "Epoch 17/75\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09011\n",
      "86/86 - 184s - loss: 0.0349 - categorical_accuracy: 0.9879 - val_loss: 0.1704 - val_categorical_accuracy: 0.9512\n",
      "Epoch 18/75\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09011\n",
      "86/86 - 183s - loss: 0.0343 - categorical_accuracy: 0.9865 - val_loss: 0.2678 - val_categorical_accuracy: 0.9192\n",
      "Epoch 19/75\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09011\n",
      "86/86 - 183s - loss: 0.0492 - categorical_accuracy: 0.9803 - val_loss: 0.1901 - val_categorical_accuracy: 0.9437\n",
      "Epoch 20/75\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09011\n",
      "86/86 - 182s - loss: 0.0521 - categorical_accuracy: 0.9821 - val_loss: 0.1806 - val_categorical_accuracy: 0.9427\n",
      "Epoch 21/75\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.09011\n",
      "86/86 - 182s - loss: 0.0351 - categorical_accuracy: 0.9880 - val_loss: 0.1364 - val_categorical_accuracy: 0.9624\n",
      "Epoch 22/75\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.09011\n",
      "86/86 - 182s - loss: 0.0360 - categorical_accuracy: 0.9872 - val_loss: 0.1749 - val_categorical_accuracy: 0.9568\n",
      "Epoch 23/75\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.09011\n",
      "86/86 - 183s - loss: 0.0473 - categorical_accuracy: 0.9844 - val_loss: 0.2015 - val_categorical_accuracy: 0.9502\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "#I train model again for increasing accuracy\n",
    "earlyStopping = EarlyStopping(mode=\"min\",verbose=1,patience=10)\n",
    "checkpointer = ModelCheckpoint(filepath=\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\" + 'alzheimerModel176x208.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 75\n",
    "batchSize = 100\n",
    "\n",
    "hist = lastCheckpoint.fit(trainData,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batchSize,\n",
    "                 validation_data = validationData,\n",
    "                 callbacks=[earlyStopping,checkpointer], verbose=2)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\" + 'alzheimerModel176x208.json', 'w') as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1536cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Fatih/Desktop/python/machine learning/alzheimer/\")\n",
    "modelToTest = tf.keras.models.load_model(\"alzheimerModel176x208.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0194c409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036 image(s) predicted at 47.544 sec\n",
      "Average predict time equals to =  0.046 sec\n",
      "Enter path where you want to save the figure:0\n",
      "0/\n",
      "Saving figure could not complete do you want to try again ?\n",
      "1 : Yes | any text except '1' : No0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[144,   0,   1,   0],\n",
       "       [  0,  10,   0,   0],\n",
       "       [  1,   0, 503,  16],\n",
       "       [  0,   0,   6, 356]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = testModel(modelToTest, testData, labels)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb4e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
